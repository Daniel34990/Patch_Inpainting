{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea32a359-ca57-4901-8782-6820b71b3c35",
   "metadata": {},
   "source": [
    "### Implémentation de Exemplar-based inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c290b29-4650-492d-9e5b-df993450923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2d3d4-58b8-49d1-b086-5d185bf089b5",
   "metadata": {},
   "source": [
    "### Etape 1a. (Identify the fill front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3f12d4-f07d-4ee7-b3be-babe4d0d206a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fleur.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Charger les images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfleur.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m mask_border \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_border.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m filled_region_mask \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilled_region_mask.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fleur.tif'"
     ]
    }
   ],
   "source": [
    "# Charger les images\n",
    "image = Image.open(\"fleur.tif\")\n",
    "mask_border = Image.open(\"mask_border.png\")\n",
    "filled_region_mask = Image.open(\"filled_region_mask.png\")\n",
    "fleurs = Image.open(\"fleur.tif\")\n",
    "\n",
    "# Convertir l'image en tableau NumPy\n",
    "mask_border = np.array(mask_border)/255\n",
    "filled_region_mask = np.array(filled_region_mask)/255\n",
    "image_np = np.mean(np.array(image),axis=2)/255\n",
    "H,W = mask_border.shape\n",
    "print(H,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2c732-dbaa-4827-b756-98aea51b0fec",
   "metadata": {},
   "source": [
    "### Etape 1.b Compute priorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1f445f-9a1d-452a-b67d-1380797808cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_image(i,j,image):\n",
    "    H,W = image.shape\n",
    "    return (0<=i<H) and (0<=j<W)\n",
    "\n",
    "def update_confidence(border_map,confidence_map,filled_region_mask,patch_size):\n",
    "    delta = patch_size//2\n",
    "    border_points = np.column_stack(np.where(border_map==1))\n",
    "    for (y,x) in border_points:\n",
    "        confidence = 0\n",
    "        for dx in range(-delta,delta+1):\n",
    "            for dy in range(-delta,delta+1):\n",
    "                ny, nx = y+dy, x+dx\n",
    "                if (is_in_image(ny,nx,border_map)) and filled_region_mask[ny,nx]==1:\n",
    "                    confidence += confidence_map[ny,nx]\n",
    "        confidence /= patch_size**2\n",
    "        confidence_map[y,x] = confidence\n",
    "\n",
    "def compute_gradient(x,y,image):\n",
    "    H,W = image.shape\n",
    "    x_minus_1 = max(0,x-1)\n",
    "    x_plus_1 = min(x+1,W-1)\n",
    "    y_plus_1 = min(H-1,y+1)\n",
    "    y_minus_1 = max(0,y-1)\n",
    "    \n",
    "    grad_x = image[y,x_plus_1] - image[y,x_minus_1]\n",
    "    grad_y = image[y_plus_1,x] - image[y_minus_1,x]\n",
    "    return grad_x, grad_y\n",
    "\n",
    "#TODO Implémenter une formule moins grossière pour la donnée\n",
    "def compute_data(border_map,image):\n",
    "    border_points = np.column_stack(np.where(border_map==1))\n",
    "    border_points_with_gradients = []\n",
    "    for (y,x) in border_points:\n",
    "        grad_x, grad_y = compute_gradient(x,y,image)\n",
    "        data_value = np.sqrt(grad_x**2+grad_y**2)\n",
    "        border_points_with_gradients.append(((y,x),data_value))\n",
    "    return border_points_with_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d159c-74d6-4e46-9c1a-233c296794f9",
   "metadata": {},
   "source": [
    "### Etape 2.a Find the patch with maximum priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1269114d-0c91-4194-a67d-6b7ec74d51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_next_pixel_by_priority(border_map,confidence_map,filled_region_mask,image,patch_size):\n",
    "    update_confidence(border_map,confidence_map,filled_region_mask,patch_size)\n",
    "    border_points_with_gradients = compute_data(border_map,image)\n",
    "    xmax, ymax = 0, 0\n",
    "    priority_max = -np.inf\n",
    "    for ((y, x), data) in border_points_with_gradients:\n",
    "        priority = confidence_map[y,x] * data\n",
    "        if priority > priority_max:\n",
    "            xmax, ymax = x, y\n",
    "            priority_max = priority\n",
    "    #print(priority_max, xmax, ymax, filled_region_mask[ymax,xmax])\n",
    "    return (xmax,ymax)\n",
    "\n",
    "def compute_mask_around_pixel(x,y,filled_region_mask,patch_size):\n",
    "    mask = np.zeros((patch_size,patch_size))\n",
    "    delta = patch_size//2\n",
    "    for dx in range(-delta,delta+1):\n",
    "        for dy in range(-delta,delta+1):\n",
    "            ny, nx = y+dy, x+dx\n",
    "            if (is_in_image(ny,nx,filled_region_mask) and filled_region_mask[ny,nx]==1) :\n",
    "                mask[dy+delta,dx+delta] = 1\n",
    "    #print(\"Mask\", np.sum(mask))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a620d2-7907-4dab-8680-cf65708617fd",
   "metadata": {},
   "source": [
    "### Etape 2.b Find the exemplar patch that minimises the SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c17864-b293-4921-8e45-b4c3c875a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_copy = np.copy(image_np)\n",
    "\n",
    "def compute_MSE(target_x,target_y,source_patch,mask,image):\n",
    "    patch_size = source_patch.shape[0]\n",
    "    H, W = image.shape\n",
    "    delta = patch_size//2\n",
    "    x_min = max(0,target_x-delta)\n",
    "    x_max = min(W,target_x+delta+1)\n",
    "    y_min = max(0,target_y-delta)\n",
    "    y_max = min(H,target_y+delta+1)\n",
    "    target_patch = np.zeros_like(source_patch)\n",
    "    target_patch[0:y_max-y_min,0:x_max-x_min] = image[y_min:y_max,x_min:x_max]\n",
    "    diff_all = (target_patch-source_patch)**2\n",
    "    diff = diff_all * mask\n",
    "    num_valid_pixel = np.sum(mask)\n",
    "    MSE = np.sum(diff) / num_valid_pixel\n",
    "    return MSE\n",
    "    \n",
    "def is_outside(i,j,filled_region_mask,patch_size):\n",
    "    delta = patch_size//2\n",
    "    H, W = filled_region_mask.shape\n",
    "    if i - delta < 0 or i + delta >= W or j - delta < 0 or j + delta >= H:\n",
    "        return False\n",
    "    considered_patch = filled_region_mask[j-delta:j+delta+1,i-delta:i+delta+1]\n",
    "    return np.sum(considered_patch)==patch_size**2\n",
    "    \n",
    "def find_best_matching_patch(x,y,mask,filled_region_mask,image,patch_size):\n",
    "    H,W = image.shape\n",
    "    delta = patch_size//2\n",
    "    min_MSE = float('inf')\n",
    "    optimal_x, optimal_y = 0, 0\n",
    "    for i in range(delta,W-delta):\n",
    "        for j in range(delta,H-delta):\n",
    "            if is_outside(i,j,filled_region_mask,patch_size):\n",
    "                source_patch = image[j-delta:j+delta+1,i-delta:i+delta+1]\n",
    "                current_MSE = compute_MSE(x,y,source_patch,mask,image)\n",
    "                if (current_MSE<min_MSE):\n",
    "                    min_MSE = current_MSE\n",
    "                    optimal_x = i\n",
    "                    optimal_y = j\n",
    "    #print(optimal_x,optimal_y,min_MSE)\n",
    "    return optimal_x, optimal_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96726d01-9d02-45fb-833e-b1dec0ed30dc",
   "metadata": {},
   "source": [
    "### Etape 2.c et 3. Copy image data from Ψqˆ to Ψpˆ + update confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0bc1901-fd06-4b13-aa52-42288e130cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "def copy_image_data(source_x,source_y,target_x,target_y,mask,filled_region_mask,image,confidence_map):\n",
    "    patch_size = mask.shape[0]\n",
    "    delta = patch_size//2\n",
    "    for i in range(-delta,delta+1):\n",
    "        for j in range(-delta,delta+1):\n",
    "            current_source_x, current_source_y = source_x+i, source_y+j\n",
    "            current_target_x, current_target_y = target_x+i, target_y+j\n",
    "            if is_in_image(current_target_y,current_target_x,filled_region_mask) and mask[j+delta,i+delta]==0:\n",
    "                image[current_target_y,current_target_x] = image[current_source_y,current_source_x]\n",
    "                filled_region_mask[current_target_y,current_target_x] = 1\n",
    "                confidence_map[current_target_y,current_target_x] = confidence_map[target_y,target_x]\n",
    "\n",
    "def update_border(filled_region_mask):\n",
    "    neighbor_kernel = np.array([[1,1,1],\n",
    "                          [1,0,1],\n",
    "                          [1,1,1]])\n",
    "    not_filled_mask = (1-filled_region_mask).astype(bool)\n",
    "    has_filled_neighbor = (convolve(filled_region_mask,neighbor_kernel,mode='constant',cval=0)>=1)\n",
    "    new_border = (not_filled_mask) & (has_filled_neighbor)\n",
    "    return new_border\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48aa92-6857-4fba-a370-21884ec9c290",
   "metadata": {},
   "source": [
    "### Final implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e88640da-349b-4f70-a993-53eb31b42c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 30306/30306 [03:35<00:00, 140.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Charger les images\n",
    "image = Image.open(\"yezhov.png\")\n",
    "mask_border = Image.open(\"mask_border.png\")\n",
    "filled_region_mask = Image.open(\"filled_region_mask.png\")\n",
    "\n",
    "# Convertir l'image en tableau NumPy\n",
    "mask_border = np.array(mask_border)/255\n",
    "filled_region_mask = np.array(filled_region_mask)/255\n",
    "image = np.mean(np.array(image),axis=2)/255\n",
    "initial_region_size = np.sum(filled_region_mask == 0)\n",
    "\n",
    "H,W = mask_border.shape\n",
    "print(np.sum(filled_region_mask == 0))\n",
    "confidence_map = np.copy(filled_region_mask)\n",
    "patch_size = 21\n",
    "step = 0\n",
    "with tqdm(total=initial_region_size) as pbar:\n",
    "    while np.sum(filled_region_mask == 0) > 0:\n",
    "        current_x, current_y = compute_next_pixel_by_priority(mask_border,confidence_map,filled_region_mask,image,patch_size)\n",
    "        mask_patch = compute_mask_around_pixel(current_x,current_y,filled_region_mask,patch_size)\n",
    "        source_x, source_y = find_best_matching_patch(current_x, current_y,mask_patch,filled_region_mask,image,patch_size)\n",
    "        copy_image_data(source_x,source_y,current_x,current_y,mask_patch,filled_region_mask,image,confidence_map)\n",
    "        mask_border = update_border(filled_region_mask)\n",
    "        cv2.imwrite(\"border.png\", mask_border * 255)\n",
    "        cv2.imwrite(\"filled.png\", filled_region_mask * 255)\n",
    "        remaining = np.sum(filled_region_mask == 0)\n",
    "        pbar.update(initial_region_size - remaining)\n",
    "        initial_region_size = remaining\n",
    "        #print(np.sum(filled_region_mask == 0))\n",
    "        step += 1\n",
    "cv2.imwrite(\"image_yezhov_inpaint.png\", image * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e514c7a-a3db-4e48-98cc-39f765c027c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
